# OllamaBatch
```
Onllama.OllamaBatch - Simple Ollama batch inference tool.
Copyright (c) 2025 Milkey Tan. Code released under the MIT License

Usage: Onllama.OllamaBatch [options]

Options:
  -?|-he|--help        Show help information.
  -i|--input <path>    Set input Jsonl path / 输入 Jsonl 路径。
  -o|--output <path>   Set output Jsonl path / 输出 Jsonl 路径。
  -m|--model <name>    Set overwrite model name / 覆盖模型名称。
  -s|--skip <number>   Set skip request ID / 跳过的请求 ID。
  -nt|--no-think       Set qwen3 no think / 设置 Qwen3 不思考 (/no_think)。
  -t|--trim-think      Set trim think tag / 修剪思考过程 (<think>)。
  -u|--uurl <URL>      Set ollama service URL / Ollama 服务端点。[http://127.0.0.1:11434]
  --timeout <minutes>  Set timeout minutes / 设置超时时间（分钟）。
```
